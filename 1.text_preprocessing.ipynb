{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Always do the forst Lower case the senetences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings  \n",
    "warnings.filterwarnings(\"ignore\")   # ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### wanted tot lower all this reviews letter\n",
    "\n",
    "data['review'] = data['review'].str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML TAG\n",
    "\n",
    "##### after srapping data from web so html tag in the data. suppose we are doing sentimate analyssi task so\n",
    "###### in thta we remove the tag. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we use regex\n",
    "\n",
    "import re\n",
    "def remove_htmla_tag(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']=data['review'].apply(remove_htmla_tag)\n",
    "data['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLS\n",
    "\n",
    "#### some urlpresent in text . no as such weghtage on that.so yoyu'll have to remove it.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"check out my https://www.youtube.com/watch?v=6C0sLtw5ctc&list=PLKnIA16_RmvZo7fp5kkIth6nRTeQQsjfX&index=3\"\n",
    "text2 = \"find out my l=page https://www.google.com/search?q=pvma+instead+of+puma&oq=pvma&gs_lcrp=EgZjaHJvbWUqBggBEAAYAzIPCAAQRRg5GIMBGLEDGIAEMgYIARAAGAMyBggCEAAYAzIGCAMQABgDMgYIBBAAGAMyBggFEAAYAzIICAYQABgDGAoyBggHEAAYAzIGCAgQABgDMgYICRAAGAPSAQg2MjA3ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8\"\n",
    "text3 = \"google search here www.google.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a function for remove urls from the text\n",
    "\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google search here '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVE PUNCTUATIONS\n",
    "##### its used for complaete language lagnuage formation. so will have to rmeove that.\n",
    "##### ?,!.,#,$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncutation(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wordnhajao'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'word.,nha,,jao?'\n",
    "\n",
    "remove_puncutation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnhajao\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start  = time.time()\n",
    "print(remove_puncutation(text))\n",
    "time1 = time.time() - start\n",
    "print(time1*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This ones is alwys take less time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnhajao\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start =time.time()\n",
    "print(remove_punc(text))\n",
    "time2 = time.time() - start\n",
    "print(time2*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply on the new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>Positive</th>\n",
       "      <th>im getting on borderlands and i will murder you all ,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2401  Borderlands  Positive  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "  im getting on borderlands and i will murder you all ,  \n",
       "0  I am coming to the borders and I will kill you...     \n",
       "1  im getting on borderlands and i will kill you ...     \n",
       "2  im coming on borderlands and i will murder you...     \n",
       "3  im getting on borderlands 2 and i will murder ...     \n",
       "4  im getting into borderlands and i can murder y...     "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_training.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>Positive</th>\n",
       "      <th>im getting on borderlands and i will murder you all ,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2401  Borderlands  Positive  \\\n",
       "74680  9200       Nvidia  Positive   \n",
       "74679  9200       Nvidia  Positive   \n",
       "74678  9200       Nvidia  Positive   \n",
       "74677  9200       Nvidia  Positive   \n",
       "74676  9200       Nvidia  Positive   \n",
       "...     ...          ...       ...   \n",
       "4      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "0      2401  Borderlands  Positive   \n",
       "\n",
       "      im getting on borderlands and i will murder you all ,  \n",
       "74680  Just like the windows partition of my Mac is l...     \n",
       "74679  Just realized between the windows partition of...     \n",
       "74678  Just realized the windows partition of my Mac ...     \n",
       "74677  Just realized that my Mac window partition is ...     \n",
       "74676  Just realized that the Windows partition of my...     \n",
       "...                                                  ...     \n",
       "4      im getting into borderlands and i can murder y...     \n",
       "3      im getting on borderlands 2 and i will murder ...     \n",
       "2      im coming on borderlands and i will murder you...     \n",
       "1      im getting on borderlands and i will kill you ...     \n",
       "0      I am coming to the borders and I will kill you...     \n",
       "\n",
       "[74681 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat word treatment\n",
    "\n",
    "##### lemme,asap,gn, eg convert into first its orignal form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           AFAIK=As Far As I Know\n",
       "1           AFK=Away From Keyboard\n",
       "2         ASAP=As Soon As Possible\n",
       "3              ATK=At The Keyboard\n",
       "4                ATM=At The Moment\n",
       "                  ...             \n",
       "81    BSAAW â€“ Big smile and a wink\n",
       "82    BWL â€“ Bursting with laughter\n",
       "83      LMAO â€“ Laughing my a** off\n",
       "84       BFF: Best friends forever\n",
       "85       CSL â€“ Canâ€™t stop laughing\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open and read the file\n",
    "chat_file = pd.read_csv('slang.txt',on_bad_lines='skip',header=None)\n",
    "chat_file[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AFAIK': 'As Far As I Know', 'AFK': 'Away From Keyboard', 'ASAP': 'As Soon As Possible', 'ATK': 'At The Keyboard', 'ATM': 'At The Moment', 'BAK': 'Back At Keyboard', 'BBL': 'Be Back Later', 'BBS': 'Be Back Soon', 'BFN': 'Bye For Now', 'B4N': 'Bye For Now', 'BRB': 'Be Right Back', 'BRT': 'Be Right There', 'BTW': 'By The Way', 'B4': 'Before', 'CU': 'See You', 'CUL8R': 'See You Later', 'CYA': 'See You', 'FAQ': 'Frequently Asked Questions', 'FC': 'Fingers Crossed', 'FWIW': \"For What It's Worth\", 'FYI': 'For Your Information', 'GAL': 'Get A Life', 'GG': 'Good Game', 'GN': 'Good Night', 'GMTA': 'Great Minds Think Alike', 'GR8': 'Great!', 'G9': 'Genius', 'IC': 'I See', 'ICQ': 'I Seek you (also a chat program)', 'ILU': 'ILU: I Love You', 'IMHO': 'In My Honest/Humble Opinion', 'IMO': 'In My Opinion', 'IOW': 'In Other Words', 'IRL': 'In Real Life', 'LDR': 'Long Distance Relationship', 'LMAO': 'Laugh My A.. Off', 'LOL': 'Laughing Out Loud', 'LTNS': 'Long Time No See', 'L8R': 'Later', 'MTE': 'My Thoughts Exactly', 'M8': 'Mate', 'NRN': 'No Reply Necessary', 'OIC': 'Oh I See', 'PITA': 'Pain In The A..', 'PRT': 'Party', 'PRW': 'Parents Are Watching', 'ROFL': 'Rolling On The Floor Laughing', 'ROFLOL': 'Rolling On The Floor Laughing Out Loud', 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off', 'SK8': 'Skate', 'STATS': 'Your sex and age', 'THX': 'Thank You', 'TTFN': 'Ta-Ta For Now!', 'TTYL': 'Talk To You Later', 'U': 'You', 'U2': 'You Too', 'U4E': 'Yours For Ever', 'WB': 'Welcome Back', 'WTF': 'What The F...', 'WTG': 'Way To Go!', 'WUF': 'Where Are You From?', 'W8': 'Wait...', '7K': 'Sick:-D Laugher'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "chat_word = {}\n",
    "\n",
    "# Process each line\n",
    "for line in chat_file[0]:\n",
    "    # Strip any leading/trailing whitespace\n",
    "    line = line.strip()\n",
    "    # Check if the line contains the delimiter\n",
    "    if '=' in line:\n",
    "        key, value = line.split('=',1)  # Split only on the first occurrence of ':'\n",
    "        \n",
    "        # Add to dictionary\n",
    "        chat_word[key] = value\n",
    "\n",
    "print(chat_word)\n",
    "\n",
    "# chat_word.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_word:\n",
    "            new_text.append(chat_word[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Honest/Humble Opinion he is the best'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('IMHO he is the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Your Information delhi is the capital of india'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('FYI delhi is the capital of india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling correction \n",
    "\n",
    "##### we have so many lib for this for specified .am using textbolob, filecheker,xpicy, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
    "\n",
    "textBlb = TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stoppwords\n",
    "\n",
    "#### a, the ,off are my used ofr making sentence foramtion but not useful in sentiment,decument analsysi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\v-mnagare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Emojis in text\n",
    "\n",
    "##### either you remoeve or replace with words meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to remove mejois\n",
    "\n",
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lmao '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Lmao ðŸ˜‚ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import emoji\n",
    "print(emoji.demojize('Python is ðŸ”¥'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the movie. It was :face_blowing_a_kiss:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('Loved the movie. It was ðŸ˜˜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "### breaking your text documents into smaller parts (chunks).smaller parts will be sentence, words,phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### you can use split function directly for small sentence or words but it has limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regex comes into picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\v-mnagare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent6 = 'I am going to visit delhi!'\n",
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT SPACY \n",
    "\n",
    "##### its better than nltk for some of the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.11-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.10-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.2.1)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.2 MB 4.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/12.2 MB 4.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.6/12.2 MB 4.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/12.2 MB 4.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/12.2 MB 3.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/12.2 MB 3.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/12.2 MB 3.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/12.2 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/12.2 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/12.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.5/12.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/12.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.7/12.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/12.2 MB 2.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.0/12.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/12.2 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.2/12.2 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.3/12.2 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/12.2 MB 2.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.5/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.7/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.8/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.0/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.1/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.3/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.5/12.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.6/12.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.7/12.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.0/12.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.1/12.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.3/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.4/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.6/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.7/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.8/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.0/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.1/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.2/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.3/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.4/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.5/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.6/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.8/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.9/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.0/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.1/12.2 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.2/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.3/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.3/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.6/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.7/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.8/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.9/12.2 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.0/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.1/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.3/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.4/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.5/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.6/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.8/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.9/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.2/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.5/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.6/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.7/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.8/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.0/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.1/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.2/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.3/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.4/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.5/12.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.6/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.8/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.1/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.3/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.6/12.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.9/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.2/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.5/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.8/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.9/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.10-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 183.0/183.0 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.11-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 3.5 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.4/2.0 MB 7.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/2.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.0 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.0-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 256.0/632.6 kB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 419.8/632.6 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 553.0/632.6 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  624.6/632.6 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 632.6/632.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 11.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB ? eta 0:00:00\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.6/134.6 kB 8.3 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.2.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/6.2 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/6.2 MB 3.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.4/6.2 MB 3.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/6.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.7/6.2 MB 2.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.8/6.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.9/6.2 MB 2.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.0/6.2 MB 2.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.1/6.2 MB 2.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.2/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.3/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.4/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.7/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.9/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.0/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.2/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.3/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.5/6.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.7/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.8/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.9/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.0/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.1/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.2/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.4/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.5/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.6/6.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.8/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.9/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.0/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.1/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.3/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.4/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.6/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.9/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.3/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.4/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.7/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.9/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 2.5 MB/s eta 0:00:00\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.4/102.4 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.4 MB 10.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.5/5.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.6/5.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.7/5.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/5.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.9/5.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.4 MB 3.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.1/5.4 MB 3.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.2/5.4 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.4 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.4/5.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.6/5.4 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.4 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.9/5.4 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.0/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.2/5.4 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.3/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.5/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.6/5.4 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.8/5.4 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.9/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.0/5.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.1/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.2/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.5/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.6/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.8/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.1/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.2/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.6/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.8/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.9/5.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.0/5.4 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.3/5.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 225.3/242.4 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 242.4/242.4 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.7/61.7 kB ? eta 0:00:00\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.4/128.4 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.0 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 122.9/152.0 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 152.0/152.0 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, urllib3, spacy-loggers, spacy-legacy, shellingham, pydantic-core, murmurhash, mdurl, MarkupSafe, marisa-trie, idna, cloudpathlib, charset-normalizer, certifi, catalogue, blis, annotated-types, srsly, smart-open, requests, pydantic, preshed, markdown-it-py, language-data, jinja2, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 certifi-2024.12.14 charset-normalizer-3.4.1 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 idna-3.10 jinja2-3.1.5 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 preshed-3.0.9 pydantic-2.10.5 pydantic-core-2.27.2 requests-2.32.3 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.0 thinc-8.3.4 typer-0.15.1 urllib3-2.3.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\v-mnagare\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\v-mnagare\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'c:\\Users\\v-mnagare\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'c:\\Users\\v-mnagare\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'c:\\Users\\v-mnagare\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement en_core_web_sm (from versions: none)\n",
      "ERROR: No matching distribution found for en_core_web_sm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    }
   ],
   "source": [
    "!pip install en_core_web_sm\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.10.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\v-mnagare\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\v-mnagare\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/12.8 MB 812.7 kB/s eta 0:00:16\n",
      "      --------------------------------------- 0.2/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.5/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.7/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.8/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.9/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.0/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.1/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.2/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 1.9/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.2/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.3/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.5/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.7/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.8/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 2.9/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.1/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.2/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.9/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.0/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.1/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.4/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.6/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.8/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.1/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.1/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.2/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.5/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.7/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.9/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.8/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 8.0/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.3/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.6/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.7/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.8/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.1/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.3/12.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.2/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walks walked walking\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
     ]
    }
   ],
   "source": [
    "text = 'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\v-mnagare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
